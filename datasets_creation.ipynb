{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1667582",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Init ###\n",
    "\n",
    "# Packages\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "min_magnitude = 0\n",
    "max_magnitude = 10\n",
    "\n",
    "min_longitude = -180\n",
    "max_longitude = 180\n",
    "\n",
    "min_latitude = -90\n",
    "max_latitude = 90\n",
    "\n",
    "min_depth = 0\n",
    "\n",
    "# Datasets paths\n",
    "dataset1_path = \"Datasets/Earthquakes-180d.csv\"\n",
    "dataset2_path = \"Datasets/Earthquakes-1990-2023.csv\"\n",
    "\n",
    "dataset1_filtered_path = dataset1_path.replace(\".csv\", \"-filtered.csv\")\n",
    "dataset2_filtered_path = dataset2_path.replace(\".csv\", \"-filtered.csv\")\n",
    "\n",
    "dataset1_filtered_18K_path = dataset1_filtered_path.replace(\".csv\", \"-18K.csv\")\n",
    "dataset2_filtered_1M_path = dataset2_filtered_path.replace(\".csv\", \"-1M.csv\")\n",
    "dataset2_filtered_2M_path = dataset2_filtered_path.replace(\".csv\", \"-2M.csv\")\n",
    "dataset2_filtered_3M_path = dataset2_filtered_path.replace(\".csv\", \"-3M.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78056a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Methods ###\n",
    "\n",
    "def filter_dataset_feature(dataset, feature_name: str, min_value: float = float(\"-inf\"), max_value: float = float(\"inf\"), include_min_max: bool = True):\n",
    "    if include_min_max:\n",
    "        return dataset[(dataset[feature_name] >= min_value) & (dataset[feature_name] <= max_value)]\n",
    "    else:\n",
    "        return dataset[(dataset[feature_name] > min_value) & (dataset[feature_name] < max_value)]\n",
    "    \n",
    "def filter_dataset(dataset):\n",
    "    # Filter magnitude\n",
    "    dataset = filter_dataset_feature(dataset, \"magnitude\", min_magnitude, max_magnitude, False)\n",
    "\n",
    "    # Filter longitude\n",
    "    dataset = filter_dataset_feature(dataset, \"longitude\", min_longitude, max_longitude, True)\n",
    "\n",
    "    # Filter latitude\n",
    "    dataset = filter_dataset_feature(dataset, \"latitude\", min_latitude, max_latitude, True)\n",
    "\n",
    "    # Filter depth\n",
    "    dataset = filter_dataset_feature(dataset, \"depth\", min_depth, include_min_max = True)\n",
    "\n",
    "    # Drop duplicates\n",
    "    dataset.drop_duplicates(inplace = True)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def print_dataset(dataset_name: str, dataset):\n",
    "    print(f\"### {dataset_name} ###\")\n",
    "    print(dataset.info())\n",
    "    print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef794a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Dataset 1 (Datasets/Earthquakes-180d) ###\n",
      "magnitude    float64\n",
      "place         object\n",
      "time_utc      object\n",
      "longitude    float64\n",
      "latitude     float64\n",
      "depth        float64\n",
      "dtype: object\n",
      "          magnitude     longitude      latitude         depth\n",
      "count  17976.000000  17976.000000  17976.000000  17976.000000\n",
      "mean       1.750055   -105.888197     36.978271     24.434512\n",
      "std        1.234165     72.183896     19.999393     55.737903\n",
      "min        0.010000   -179.976700    -63.573800      0.000000\n",
      "25%        0.840000   -143.020250     33.325208      3.800000\n",
      "50%        1.500000   -119.995900     38.792500      8.120000\n",
      "75%        2.160000   -110.573042     47.948000     15.592500\n",
      "max        7.400000    179.997000     87.027900    667.237000\n",
      "Number of rows: 17976\n"
     ]
    }
   ],
   "source": [
    "### Creation of filtered dataset 1 ###\n",
    "\n",
    "dataset1 = pd.read_csv(dataset1_path)\n",
    "\n",
    "# Features selection\n",
    "dataset1.drop(columns = [\"id\", \"url\"], inplace = True)\n",
    "\n",
    "# Rename features\n",
    "dataset1.rename(columns = {\"mag\": \"magnitude\", \"depth_km\": \"depth\"}, inplace = True)\n",
    "\n",
    "# Filter dataset\n",
    "dataset1 = filter_dataset(dataset1)\n",
    "\n",
    "# Reset index\n",
    "dataset1.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Save dataset\n",
    "dataset1.to_csv(dataset1_filtered_path, index = False)\n",
    "\n",
    "# Print dataset\n",
    "print_dataset(f\"Dataset 1 ({dataset1_path.replace(\".csv\", \"\")})\", dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0cfe1592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Dataset 2 (Datasets/Earthquakes-1990-2023) ###\n",
      "place         object\n",
      "magnitude    float64\n",
      "state         object\n",
      "longitude    float64\n",
      "latitude     float64\n",
      "depth        float64\n",
      "date          object\n",
      "dtype: object\n",
      "          magnitude     longitude      latitude         depth\n",
      "count  3.124451e+06  3.124451e+06  3.124451e+06  3.124451e+06\n",
      "mean   1.866789e+00 -9.961537e+01  3.713725e+01  2.468049e+01\n",
      "std    1.268102e+00  7.936165e+01  2.101365e+01  5.668386e+01\n",
      "min    1.000000e-02 -1.799997e+02 -8.442200e+01  0.000000e+00\n",
      "25%    9.900000e-01 -1.471574e+02  3.394867e+01  3.970000e+00\n",
      "50%    1.500000e+00 -1.189430e+02  3.774100e+01  8.500000e+00\n",
      "75%    2.400000e+00 -1.156255e+02  5.068300e+01  1.848200e+01\n",
      "max    9.100000e+00  1.800000e+02  8.738600e+01  7.358000e+02\n",
      "Number of rows: 3124451\n"
     ]
    }
   ],
   "source": [
    "### Creation of filtered dataset 2 ###\n",
    "\n",
    "dataset2 = pd.read_csv(dataset2_path)\n",
    "\n",
    "# Features selection\n",
    "dataset2.drop(columns = [\"time\", \"status\", \"tsunami\", \"significance\"], inplace = True)\n",
    "\n",
    "# Rename features\n",
    "dataset2.rename(columns = {\"magnitudo\": \"magnitude\"}, inplace = True)\n",
    "\n",
    "# Filter earthquakes\n",
    "dataset2 = dataset2[dataset2[\"data_type\"] == \"earthquake\"]\n",
    "\n",
    "dataset2.drop(columns = [\"data_type\"], inplace = True)\n",
    "\n",
    "# Filter dataset\n",
    "dataset2 = filter_dataset(dataset2)\n",
    "\n",
    "# Reset index\n",
    "dataset2.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Save dataset\n",
    "dataset2.to_csv(dataset2_filtered_path, index = False)\n",
    "\n",
    "# Print dataset\n",
    "print_dataset(f\"Dataset 2 ({dataset2_path.replace(\".csv\", \"\")})\", dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1cc5435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creation of filtered dataset 18K from dataset 1 ###\n",
    "\n",
    "dataset1_filtered = pd.read_csv(dataset1_filtered_path)\n",
    "\n",
    "# Sample dataset\n",
    "dataset1_filtered_18K = dataset1_filtered.sample(frac = 1)\n",
    "\n",
    "# Reset index\n",
    "dataset1_filtered_18K.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Save dataset\n",
    "dataset1_filtered_18K.to_csv(dataset1_filtered_18K_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8fa62206",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creation of filtered datasets 1M, 2M and 3M from dataset 2 ###\n",
    "\n",
    "dataset2_filtered = pd.read_csv(dataset2_filtered_path)\n",
    "\n",
    "# Sample datasets\n",
    "dataset2_filtered_1M = dataset2_filtered.sample(n = int(1e6))\n",
    "dataset2_filtered_2M = dataset2_filtered.sample(n = int(2e6))\n",
    "dataset2_filtered_3M = dataset2_filtered.sample(n = int(3e6))\n",
    "\n",
    "# Reset index\n",
    "dataset2_filtered_1M.reset_index(drop = True, inplace = True)\n",
    "dataset2_filtered_2M.reset_index(drop = True, inplace = True)\n",
    "dataset2_filtered_3M.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Save datasets\n",
    "dataset2_filtered_1M.to_csv(dataset2_filtered_1M_path, index = False)\n",
    "dataset2_filtered_2M.to_csv(dataset2_filtered_2M_path, index = False)\n",
    "dataset2_filtered_3M.to_csv(dataset2_filtered_3M_path, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
