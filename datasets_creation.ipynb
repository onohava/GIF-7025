{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1667582",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Init ###\n",
    "\n",
    "# Packages\n",
    "from typing import List, Dict, Callable, Any\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "min_magnitude = 0\n",
    "max_magnitude = 10\n",
    "\n",
    "min_longitude = -180\n",
    "max_longitude = 180\n",
    "\n",
    "min_latitude = -90\n",
    "max_latitude = 90\n",
    "\n",
    "min_depth = 0\n",
    "\n",
    "shuffle_seed = 42\n",
    "\n",
    "# Datasets paths\n",
    "datasets_paths = []\n",
    "\n",
    "datasets_paths.append(\"Datasets/Earthquakes-180d.csv\") # Earthquakes-180d Dataset\n",
    "datasets_paths.append(\"Datasets/Earthquakes-1990-2023.csv\") # Earthquakes-1990-2023 Dataset\n",
    "\n",
    "remove_features = {}\n",
    "\n",
    "remove_features[datasets_paths[0]] = [\"id\", \"url\"]\n",
    "remove_features[datasets_paths[1]] = [\"time\", \"state\", \"status\", \"tsunami\", \"significance\", \"data_type\"]\n",
    "\n",
    "rename_features = {}\n",
    "\n",
    "rename_features[datasets_paths[0]] = {\"mag\": \"magnitude\", \"depth_km\": \"depth\", \"time_utc\": \"date\"}\n",
    "rename_features[datasets_paths[1]] = {\"magnitudo\": \"magnitude\"}\n",
    "\n",
    "datasets_filtered_paths = {dataset_path: dataset_path.replace(\".csv\", \"-filtered.csv\") for dataset_path in datasets_paths}\n",
    "\n",
    "datasets_filtered_subsets_sizes = {}\n",
    "\n",
    "datasets_filtered_subsets_sizes[datasets_paths[0]] = {\"18K\": 18000}\n",
    "datasets_filtered_subsets_sizes[datasets_paths[1]] = {\"1M\": int(1e6), \"2M\": int(2e6), \"3M\": int(3e6)}\n",
    "\n",
    "datasets_filtered_subsets_paths = {dataset_path: {dataset_filtered_subset_name:\n",
    "                                   datasets_filtered_paths[dataset_path].replace(\".csv\", \"-\" + dataset_filtered_subset_name + \".csv\")\n",
    "                                   for dataset_filtered_subset_name in datasets_filtered_subsets_sizes[dataset_path].keys()}\n",
    "                                   for dataset_path in datasets_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78056a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Methods ###\n",
    "\n",
    "def filter_dataset_feature(dataset, feature_name: str, min_value: float = float(\"-inf\"), max_value: float = float(\"inf\"), include_min_max: bool = True):\n",
    "    if include_min_max:\n",
    "        return dataset[(dataset[feature_name] >= min_value) & (dataset[feature_name] <= max_value)]\n",
    "    else:\n",
    "        return dataset[(dataset[feature_name] > min_value) & (dataset[feature_name] < max_value)]\n",
    "    \n",
    "def filter_dataset(dataset):\n",
    "    # Filter magnitude\n",
    "    dataset = filter_dataset_feature(dataset, \"magnitude\", min_magnitude, max_magnitude, False)\n",
    "\n",
    "    # Filter longitude\n",
    "    dataset = filter_dataset_feature(dataset, \"longitude\", min_longitude, max_longitude, True)\n",
    "\n",
    "    # Filter latitude\n",
    "    dataset = filter_dataset_feature(dataset, \"latitude\", min_latitude, max_latitude, True)\n",
    "\n",
    "    # Filter depth\n",
    "    dataset = filter_dataset_feature(dataset, \"depth\", min_depth, include_min_max = True)\n",
    "\n",
    "    # Substitutions\n",
    "    dataset[\"place\"] = dataset[\"place\"].map(lambda place: place.replace(\"CA\", \"California\"))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def print_dataset(dataset_name: str, dataset):\n",
    "    print(f\"### {dataset_name} ###\")\n",
    "    print(dataset.info())\n",
    "    print(dataset.describe())\n",
    "\n",
    "def create_filtered_dataset(dataset, remove_features: List[str], rename_features: Dict[str, str],\n",
    "                            filter_dataset: Callable = filter_dataset):\n",
    "    # Rename features\n",
    "    dataset.rename(columns = rename_features, inplace = True)\n",
    "\n",
    "    # Filter dataset\n",
    "    dataset = filter_dataset(dataset)\n",
    "\n",
    "    # Features selection\n",
    "    dataset.drop(columns = remove_features, inplace = True)\n",
    "\n",
    "    # Drop duplicates\n",
    "    dataset.drop_duplicates(inplace = True)\n",
    "\n",
    "    # Reset index\n",
    "    dataset.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def create_dataset(dataset, dataset_path: str, create_dataset: Callable, create_dataset_params: Dict[str, Any],\n",
    "                   load_dataset: bool = True, save_dataset: bool = True):\n",
    "    print(f\"Start of creation of dataset ({dataset_path})\")\n",
    "    \n",
    "    # Load dataset\n",
    "    if load_dataset: dataset = pd.read_csv(dataset)\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = create_dataset(dataset, **create_dataset_params)\n",
    "\n",
    "    # Save dataset\n",
    "    if save_dataset: dataset.to_csv(dataset_path, index = False)\n",
    "\n",
    "    print(f\"End of creation of dataset ({dataset_path})\")\n",
    "\n",
    "    # Print dataset\n",
    "    print_dataset(f\"Dataset ({dataset_path.replace(\".csv\", \"\")})\", dataset)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def create_subset(dataset, subset_size: int):\n",
    "    # Sample dataset\n",
    "    subset = dataset.sample(n = (subset_size if subset_size <= len(dataset) else len(dataset)), random_state = shuffle_seed)\n",
    "\n",
    "    # Reset index\n",
    "    subset.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb1fb659",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filters ###\n",
    "\n",
    "def filter_dataset2(dataset):\n",
    "    # Filter earthquakes\n",
    "    dataset = dataset[dataset[\"data_type\"] == \"earthquake\"]\n",
    "    \n",
    "    # Filter dataset\n",
    "    dataset = filter_dataset(dataset)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "filter_datasets = {}\n",
    "\n",
    "filter_datasets[datasets_paths[0]] = filter_dataset\n",
    "filter_datasets[datasets_paths[1]] = filter_dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6a643fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of creation of dataset (Datasets/Earthquakes-180d-filtered.csv)\n",
      "End of creation of dataset (Datasets/Earthquakes-180d-filtered.csv)\n",
      "### Dataset (Datasets/Earthquakes-180d-filtered) ###\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17976 entries, 0 to 17975\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   magnitude  17976 non-null  float64\n",
      " 1   place      17976 non-null  object \n",
      " 2   date       17976 non-null  object \n",
      " 3   longitude  17976 non-null  float64\n",
      " 4   latitude   17976 non-null  float64\n",
      " 5   depth      17976 non-null  float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 842.8+ KB\n",
      "None\n",
      "          magnitude     longitude      latitude         depth\n",
      "count  17976.000000  17976.000000  17976.000000  17976.000000\n",
      "mean       1.750055   -105.888197     36.978271     24.434512\n",
      "std        1.234165     72.183896     19.999393     55.737903\n",
      "min        0.010000   -179.976700    -63.573800      0.000000\n",
      "25%        0.840000   -143.020250     33.325208      3.800000\n",
      "50%        1.500000   -119.995900     38.792500      8.120000\n",
      "75%        2.160000   -110.573042     47.948000     15.592500\n",
      "max        7.400000    179.997000     87.027900    667.237000\n",
      "Start of creation of dataset (Datasets/Earthquakes-1990-2023-filtered.csv)\n",
      "End of creation of dataset (Datasets/Earthquakes-1990-2023-filtered.csv)\n",
      "### Dataset (Datasets/Earthquakes-1990-2023-filtered) ###\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3124451 entries, 0 to 3124450\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   place      object \n",
      " 1   magnitude  float64\n",
      " 2   longitude  float64\n",
      " 3   latitude   float64\n",
      " 4   depth      float64\n",
      " 5   date       object \n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 143.0+ MB\n",
      "None\n",
      "          magnitude     longitude      latitude         depth\n",
      "count  3.124451e+06  3.124451e+06  3.124451e+06  3.124451e+06\n",
      "mean   1.866789e+00 -9.961537e+01  3.713725e+01  2.468049e+01\n",
      "std    1.268102e+00  7.936165e+01  2.101365e+01  5.668386e+01\n",
      "min    1.000000e-02 -1.799997e+02 -8.442200e+01  0.000000e+00\n",
      "25%    9.900000e-01 -1.471574e+02  3.394867e+01  3.970000e+00\n",
      "50%    1.500000e+00 -1.189430e+02  3.774100e+01  8.500000e+00\n",
      "75%    2.400000e+00 -1.156255e+02  5.068300e+01  1.848200e+01\n",
      "max    9.100000e+00  1.800000e+02  8.738600e+01  7.358000e+02\n"
     ]
    }
   ],
   "source": [
    "### Create filtered datasets ###\n",
    "\n",
    "datasets_filtered = {dataset_path: create_dataset(dataset_path, datasets_filtered_paths[dataset_path], create_filtered_dataset,\n",
    "                     {\"remove_features\": remove_features[dataset_path], \"rename_features\": rename_features[dataset_path],\n",
    "                      \"filter_dataset\": filter_datasets[dataset_path]})\n",
    "                     for dataset_path in datasets_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43a040cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load filtered datasets ###\n",
    "\n",
    "datasets_filtered = {dataset_path: pd.read_csv(datasets_filtered_paths[dataset_path]) for dataset_path in datasets_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b29a8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of creation of dataset (Datasets/Earthquakes-180d-filtered-18K.csv)\n",
      "End of creation of dataset (Datasets/Earthquakes-180d-filtered-18K.csv)\n",
      "### Dataset (Datasets/Earthquakes-180d-filtered-18K) ###\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17976 entries, 0 to 17975\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   magnitude  17976 non-null  float64\n",
      " 1   place      17976 non-null  object \n",
      " 2   date       17976 non-null  object \n",
      " 3   longitude  17976 non-null  float64\n",
      " 4   latitude   17976 non-null  float64\n",
      " 5   depth      17976 non-null  float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 842.8+ KB\n",
      "None\n",
      "          magnitude     longitude      latitude         depth\n",
      "count  17976.000000  17976.000000  17976.000000  17976.000000\n",
      "mean       1.750055   -105.888197     36.978271     24.434512\n",
      "std        1.234165     72.183896     19.999393     55.737903\n",
      "min        0.010000   -179.976700    -63.573800      0.000000\n",
      "25%        0.840000   -143.020250     33.325208      3.800000\n",
      "50%        1.500000   -119.995900     38.792500      8.120000\n",
      "75%        2.160000   -110.573042     47.948000     15.592500\n",
      "max        7.400000    179.997000     87.027900    667.237000\n",
      "Start of creation of dataset (Datasets/Earthquakes-1990-2023-filtered-1M.csv)\n",
      "End of creation of dataset (Datasets/Earthquakes-1990-2023-filtered-1M.csv)\n",
      "### Dataset (Datasets/Earthquakes-1990-2023-filtered-1M) ###\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count    Dtype  \n",
      "---  ------     --------------    -----  \n",
      " 0   place      1000000 non-null  object \n",
      " 1   magnitude  1000000 non-null  float64\n",
      " 2   longitude  1000000 non-null  float64\n",
      " 3   latitude   1000000 non-null  float64\n",
      " 4   depth      1000000 non-null  float64\n",
      " 5   date       1000000 non-null  object \n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 45.8+ MB\n",
      "None\n",
      "            magnitude       longitude        latitude           depth\n",
      "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000\n",
      "mean         1.867260      -99.618685       37.126706       24.639028\n",
      "std          1.268095       79.388557       21.041770       56.552090\n",
      "min          0.010000     -179.999000      -84.422000        0.000000\n",
      "25%          0.990000     -147.176200       33.951500        3.975000\n",
      "50%          1.500000     -118.943667       37.715700        8.500000\n",
      "75%          2.400000     -115.632650       50.845025       18.500000\n",
      "max          9.100000      180.000000       87.375200      735.800000\n",
      "Start of creation of dataset (Datasets/Earthquakes-1990-2023-filtered-2M.csv)\n",
      "End of creation of dataset (Datasets/Earthquakes-1990-2023-filtered-2M.csv)\n",
      "### Dataset (Datasets/Earthquakes-1990-2023-filtered-2M) ###\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000000 entries, 0 to 1999999\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   place      object \n",
      " 1   magnitude  float64\n",
      " 2   longitude  float64\n",
      " 3   latitude   float64\n",
      " 4   depth      float64\n",
      " 5   date       object \n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 91.6+ MB\n",
      "None\n",
      "          magnitude     longitude      latitude         depth\n",
      "count  2.000000e+06  2.000000e+06  2.000000e+06  2.000000e+06\n",
      "mean   1.866692e+00 -9.961108e+01  3.715304e+01  2.467108e+01\n",
      "std    1.267923e+00  7.938937e+01  2.099273e+01  5.664618e+01\n",
      "min    1.000000e-02 -1.799990e+02 -8.442200e+01  0.000000e+00\n",
      "25%    9.900000e-01 -1.471567e+02  3.395100e+01  3.960000e+00\n",
      "50%    1.500000e+00 -1.189433e+02  3.775000e+01  8.500000e+00\n",
      "75%    2.400000e+00 -1.156290e+02  5.075505e+01  1.841000e+01\n",
      "max    9.100000e+00  1.800000e+02  8.738600e+01  7.358000e+02\n",
      "Start of creation of dataset (Datasets/Earthquakes-1990-2023-filtered-3M.csv)\n",
      "End of creation of dataset (Datasets/Earthquakes-1990-2023-filtered-3M.csv)\n",
      "### Dataset (Datasets/Earthquakes-1990-2023-filtered-3M) ###\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000000 entries, 0 to 2999999\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   place      object \n",
      " 1   magnitude  float64\n",
      " 2   longitude  float64\n",
      " 3   latitude   float64\n",
      " 4   depth      float64\n",
      " 5   date       object \n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 137.3+ MB\n",
      "None\n",
      "          magnitude     longitude      latitude         depth\n",
      "count  3.000000e+06  3.000000e+06  3.000000e+06  3.000000e+06\n",
      "mean   1.866946e+00 -9.960865e+01  3.713763e+01  2.469471e+01\n",
      "std    1.268231e+00  7.936694e+01  2.101206e+01  5.672650e+01\n",
      "min    1.000000e-02 -1.799997e+02 -8.442200e+01  0.000000e+00\n",
      "25%    9.900000e-01 -1.471597e+02  3.394800e+01  3.970000e+00\n",
      "50%    1.500000e+00 -1.189427e+02  3.773900e+01  8.500000e+00\n",
      "75%    2.400000e+00 -1.156250e+02  5.068300e+01  1.850000e+01\n",
      "max    9.100000e+00  1.800000e+02  8.738600e+01  7.358000e+02\n"
     ]
    }
   ],
   "source": [
    "### Create filtered datasets subsets ###\n",
    "\n",
    "datasets_filtered_subsets = {dataset_path: {dataset_filtered_subset_name: create_dataset(datasets_filtered[dataset_path],\n",
    "                             datasets_filtered_subsets_paths[dataset_path][dataset_filtered_subset_name],\n",
    "                             create_subset, {\"subset_size\": dataset_filtered_subset_size}, False)\n",
    "                             for (dataset_filtered_subset_name, dataset_filtered_subset_size) in datasets_filtered_subsets_sizes[dataset_path].items()}\n",
    "                             for dataset_path in datasets_paths}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
