{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118512c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Init ###\n",
    "\n",
    "# Packages\n",
    "from typing import Callable, Any, Dict, List\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, TrainerCallback\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import os, json\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Constants\n",
    "earthquake_prompt_features = [\"DATE\", \"PLACE\", \"LATITUDE\", \"LONGITUDE\", \"DEPTH\"]\n",
    "earthquake_prompt_template = \"on DATE utc, an earthquake struck at PLACE. the epicenter was located at latitude LATITUDE, longitude LONGITUDE, with a depth of DEPTH km beneath the earth's surface.\"\n",
    "\n",
    "train_test_split = 0.6\n",
    "eval_test_split = 0.5\n",
    "\n",
    "logging_steps_epochs = 1/3\n",
    "\n",
    "save_strategy = \"epoch\"\n",
    "save_steps = 0\n",
    "save_total_limit = 3\n",
    "\n",
    "load_checkpoint = 0\n",
    "\n",
    "num_train_epochs = 3\n",
    "per_device_train_batch_size = 8\n",
    "per_device_eval_batch_size = per_device_train_batch_size\n",
    "\n",
    "shuffle_seed = 42\n",
    "\n",
    "num_proc = os.cpu_count()\n",
    "\n",
    "# Models paths\n",
    "models_paths = []\n",
    "\n",
    "models_paths.append(\"distilbert/distilbert-base-uncased\") # Distilbert-base-uncased: 67M params\n",
    "# models_paths.append(\"FacebookAI/roberta-base\") # Roberta-base: 110M params\n",
    "# models_paths.append(\"google-bert/bert-base-uncased\") # Bert-base-uncased: 110M params\n",
    "# models_paths.append(\"google-bert/bert-large-uncased\") # Bert-large-uncased: 340M params\n",
    "\n",
    "# Datasets paths\n",
    "datasets_paths = []\n",
    "\n",
    "# datasets_paths.append(\"Datasets/Earthquakes-180d-filtered.csv\") # Earthquakes-180d Dataset\n",
    "datasets_paths.append(\"Datasets/Earthquakes-1990-2023-filtered.csv\") # Earthquakes-1990-2023 Dataset\n",
    "\n",
    "datasets_prompts_paths = {dataset_path: dataset_path.replace(\"filtered\", \"prompts\") for dataset_path in datasets_paths}\n",
    "\n",
    "datasets_prompts_tokenized_paths = {dataset_path: {model_path: datasets_prompts_paths[dataset_path].replace(\".csv\", f\"-tokenized/{model_path.lower()}.parquet\")\n",
    "                                    for model_path in models_paths} for dataset_path in datasets_paths}\n",
    "\n",
    "datasets_prompts_tokenized_subsets_sizes = {}\n",
    "\n",
    "# datasets_prompts_tokenized_subsets_sizes[datasets_paths[0]] = {\"18K\": 18000}\n",
    "# datasets_prompts_tokenized_subsets_sizes[datasets_paths[1]] = {\"1M\": int(1e6), \"2M\": int(2e6), \"3M\": int(3e6)}\n",
    "datasets_prompts_tokenized_subsets_sizes[datasets_paths[0]] = {\"1M\": int(1e6)}\n",
    "\n",
    "datasets_prompts_tokenized_subsets_paths = {dataset_path: {model_path: {dataset_prompts_tokenized_subset_name:\n",
    "                                   datasets_prompts_tokenized_paths[dataset_path][model_path].replace(\".parquet\", \"-\" + dataset_prompts_tokenized_subset_name + \".parquet\")\n",
    "                                   for dataset_prompts_tokenized_subset_name in datasets_prompts_tokenized_subsets_sizes[dataset_path].keys()}\n",
    "                                   for model_path in models_paths} for dataset_path in datasets_paths}\n",
    "\n",
    "datasets_subsets_logging_steps = {dataset_path: {dataset_prompts_tokenized_subset_name: int(logging_steps_epochs * train_test_split * datasets_prompts_tokenized_subsets_sizes[dataset_path][dataset_prompts_tokenized_subset_name]/per_device_eval_batch_size)\n",
    "                                   for dataset_prompts_tokenized_subset_name in datasets_prompts_tokenized_subsets_sizes[dataset_path].keys()}\n",
    "                                   for dataset_path in datasets_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f54aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Methods ###\n",
    "\n",
    "def load_dataset_from_file(dataset_path: str):\n",
    "    return load_dataset(dataset_path.split(\".\")[-1], data_files = dataset_path)[\"train\"]\n",
    "\n",
    "def load_model(model_path: str):\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_path, num_labels = 1)\n",
    "\n",
    "def create_dataset(dataset, dataset_path: str, create_dataset: Callable, create_dataset_params: Dict[str, Any],\n",
    "                   load_dataset: bool = True, save_dataset: bool = True):\n",
    "    print(f\"Start of creation of dataset ({dataset_path})\")\n",
    "    \n",
    "    # Load dataset\n",
    "    if load_dataset: dataset = load_dataset_from_file(dataset)\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = create_dataset(dataset, **create_dataset_params)\n",
    "\n",
    "    # Save dataset\n",
    "    if save_dataset:\n",
    "        if dataset_path.endswith(\".csv\"): dataset.to_csv(dataset_path)\n",
    "        elif dataset_path.endswith(\".parquet\"): dataset.to_parquet(dataset_path)\n",
    "\n",
    "    print(f\"End of creation of dataset ({dataset_path})\")\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def create_prompts_dataset(dataset, prompt_template: str, prompt_features: List[str], target_feature: str):\n",
    "    \n",
    "    # Packages\n",
    "    from functools import reduce\n",
    "\n",
    "    remove_features = dataset.column_names\n",
    "\n",
    "    def create_prompt(instance):\n",
    "        features = {prompt_feature: str(instance[prompt_feature.lower()]).lower() for prompt_feature in prompt_features}\n",
    "        prompt = reduce(lambda prompt, feature: prompt.replace(*feature, 1), features.items(), prompt_template)\n",
    "        \n",
    "        return {\"prompt\": prompt, \"labels\": instance[target_feature]}\n",
    "    \n",
    "    dataset_prompts = dataset.map(create_prompt, num_proc = num_proc)\n",
    "    dataset_prompts = dataset_prompts.remove_columns(remove_features)\n",
    "\n",
    "    return dataset_prompts\n",
    "\n",
    "def create_train_eval_test_datasets(dataset):\n",
    "    train_test_dataset = dataset.train_test_split(test_size = 1 - train_test_split, seed = shuffle_seed)\n",
    "    eval_test_dataset = train_test_dataset[\"test\"].train_test_split(test_size = 1 - eval_test_split, seed = shuffle_seed)\n",
    "    return DatasetDict({\"train\": train_test_dataset[\"train\"], \"eval\": eval_test_dataset[\"train\"], \"test\": eval_test_dataset[\"test\"]})\n",
    "\n",
    "def create_tokenized_dataset(dataset, tokenizer):\n",
    "    return dataset.map(lambda instance: tokenizer(instance[\"prompt\"], padding = \"max_length\", truncation = True), batched = True, num_proc = num_proc)\n",
    "\n",
    "def create_subset(dataset, subset_size: int):\n",
    "    # Sample dataset\n",
    "    return dataset.shuffle(seed = shuffle_seed).select(range(subset_size if subset_size <= len(dataset) else len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf75ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load models ###\n",
    "\n",
    "models = {}\n",
    "models_tokenizers = {}\n",
    "\n",
    "for model_path in models_paths:\n",
    "    models[model_path] = load_model(model_path)\n",
    "    models_tokenizers[model_path] = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    models_tokenizers[model_path].max_length = models[model_path].config.max_position_embeddings\n",
    "\n",
    "    print(f\"### ({model_path}) Model Configuration ###\")\n",
    "    print(models[model_path].config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b8a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create prompts datasets ###\n",
    "\n",
    "datasets_prompts = {dataset_path: create_dataset(dataset_path, datasets_prompts_paths[dataset_path], create_prompts_dataset,\n",
    "                    {\"prompt_template\": earthquake_prompt_template, \"prompt_features\": earthquake_prompt_features, \"target_feature\": \"magnitude\"},\n",
    "                    True, False)\n",
    "                    for dataset_path in datasets_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ee824",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load prompts datasets ###\n",
    "\n",
    "datasets_prompts = {dataset_path: load_dataset_from_file(datasets_prompts_paths[dataset_path]) for dataset_path in datasets_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e87677",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create prompts tokenized datasets ###\n",
    "\n",
    "datasets_prompts_tokenized = {dataset_path: {model_path: create_dataset(datasets_prompts[dataset_path],\n",
    "                              datasets_prompts_tokenized_paths[dataset_path][model_path], create_tokenized_dataset,\n",
    "                              {\"tokenizer\": models_tokenizers[model_path]}, False, False)\n",
    "                              for model_path in models_paths} for dataset_path in datasets_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a2761",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load prompts tokenized datasets ###\n",
    "\n",
    "datasets_prompts_tokenized = {dataset_path: {model_path: load_dataset_from_file(datasets_prompts_tokenized_paths[dataset_path][model_path])\n",
    "                              for model_path in models_paths} for dataset_path in datasets_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37be3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create prompts tokenized datasets subsets ###\n",
    "\n",
    "datasets_prompts_tokenized_subsets = {dataset_path: {model_path: {dataset_prompts_tokenized_subset_name: create_dataset(datasets_prompts_tokenized[dataset_path][model_path],\n",
    "                                      datasets_prompts_tokenized_subsets_paths[dataset_path][model_path][dataset_prompts_tokenized_subset_name],\n",
    "                                      create_subset, {\"subset_size\": dataset_prompts_tokenized_subset_size}, False, False)\n",
    "                                      for (dataset_prompts_tokenized_subset_name, dataset_prompts_tokenized_subset_size) in datasets_prompts_tokenized_subsets_sizes[dataset_path].items()}\n",
    "                                      for model_path in models_paths} for dataset_path in datasets_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431c9089",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load prompts tokenized datasets subsets ###\n",
    "\n",
    "datasets_prompts_tokenized_subsets = {dataset_path: {model_path: {dataset_prompts_tokenize_subset_name:\n",
    "                                      load_dataset_from_file(datasets_prompts_tokenized_subsets_paths[dataset_path][model_path][dataset_prompts_tokenize_subset_name])\n",
    "                                      for dataset_prompts_tokenize_subset_name in datasets_prompts_tokenized_subsets_sizes[dataset_path].keys()}\n",
    "                                      for model_path in models_paths} for dataset_path in datasets_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7a3bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create train, eval and test datasets ###\n",
    "\n",
    "datasets_prompts_tokenized_subsets_split = {dataset_path: {model_path: {dataset_prompts_tokenize_subset_name:\n",
    "                                            create_dataset(datasets_prompts_tokenized_subsets[dataset_path][model_path][dataset_prompts_tokenize_subset_name],\n",
    "                                            datasets_prompts_tokenized_subsets_paths[dataset_path][model_path][dataset_prompts_tokenize_subset_name],\n",
    "                                            create_train_eval_test_datasets, {}, False, False)\n",
    "                                            for dataset_prompts_tokenize_subset_name in datasets_prompts_tokenized_subsets_sizes[dataset_path].keys()}\n",
    "                                            for model_path in models_paths} for dataset_path in datasets_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8de6791",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Models training methods ###\n",
    "\n",
    "mse = evaluate.load(\"mse\")\n",
    "\n",
    "def compute_mse(eval_prediction):\n",
    "    logits, labels = eval_prediction\n",
    "    if isinstance(logits, tuple): logits = logits[0]\n",
    "    return mse.compute(predictions = logits, references = labels)\n",
    "\n",
    "class TestEvalCallback(TrainerCallback):\n",
    "    def __init__(self, dataset, model_trainer):\n",
    "        self.test_dataset = dataset[\"test\"]\n",
    "        self.model_trainer = model_trainer\n",
    "        self.test_results = []\n",
    "\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        test_result = self.model_trainer.evaluate(eval_dataset = self.test_dataset)\n",
    "        test_result = {\"epoch\": state.epoch, \"step\": state.global_step, \"test_result\": test_result}\n",
    "        self.test_results.append(test_result)\n",
    "        print(test_result)\n",
    "    \n",
    "    def on_log(self, args, state, control, logs = None, **kwargs):\n",
    "        if logs and \"loss\" in logs:\n",
    "            test_result = self.model_trainer.evaluate(eval_dataset = self.test_dataset)\n",
    "            test_result = {\"epoch\": state.epoch, \"step\": state.global_step, \"test_result\": test_result}\n",
    "            self.test_results.append(test_result)\n",
    "            print(test_result)\n",
    "\n",
    "    def on_save(self, args, state, control, **kwargs):\n",
    "        checkpoint_dir = os.path.join(args.output_dir, f\"checkpoint-{state.global_step}\")\n",
    "        os.makedirs(checkpoint_dir, exist_ok = True)\n",
    "        save_path = os.path.join(checkpoint_dir, \"test_results.json\")\n",
    "        with open(save_path, \"w\") as file:\n",
    "            json.dump(self.test_results, file, indent = 2)\n",
    "\n",
    "def train_model(model_path: str, model_name: str, logging_steps: int, tokenized_dataset):\n",
    "    model_trainer = Trainer(\n",
    "        model_init = (lambda: load_model(model_path)),\n",
    "        args = TrainingArguments(\n",
    "            output_dir = model_name,\n",
    "            eval_strategy = \"steps\",\n",
    "            logging_steps = logging_steps,\n",
    "            save_strategy = save_strategy,\n",
    "            save_steps = save_steps,\n",
    "            save_total_limit = save_total_limit,\n",
    "            per_device_train_batch_size = per_device_train_batch_size,\n",
    "            per_device_eval_batch_size = per_device_eval_batch_size,\n",
    "            num_train_epochs = num_train_epochs,\n",
    "            seed = shuffle_seed,\n",
    "            data_seed = shuffle_seed),\n",
    "        train_dataset = tokenized_dataset[\"train\"],\n",
    "        eval_dataset = tokenized_dataset[\"eval\"],\n",
    "        compute_metrics = compute_mse,\n",
    "    )\n",
    "\n",
    "    model_tester = TestEvalCallback(tokenized_dataset, model_trainer)\n",
    "\n",
    "    model_trainer.add_callback(model_tester)\n",
    "\n",
    "    if \"/checkpoint-\" in model_path: model_trainer.train(resume_from_checkpoint = model_path)\n",
    "    else: model_trainer.train()\n",
    "\n",
    "    return (model_trainer.model, model_tester.test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4a9376",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train models ###\n",
    "\n",
    "trained_models = {}\n",
    "trained_models_subsets_datasets_tests_results = {}\n",
    "\n",
    "for dataset_path in datasets_paths:\n",
    "    trained_models[dataset_path] = {}\n",
    "    trained_models_subsets_datasets_tests_results[dataset_path] = {}\n",
    "    \n",
    "    for model_path in models_paths:\n",
    "        trained_models[dataset_path][model_path] = {}\n",
    "        trained_models_subsets_datasets_tests_results[dataset_path][model_path] = {}\n",
    "        \n",
    "        for (dataset_prompts_tokenized_subset_split_name, dataset_prompts_tokenized_subset_split) in datasets_prompts_tokenized_subsets_split[dataset_path][model_path].items():\n",
    "            model_name = \"\".join(datasets_prompts_tokenized_subsets_paths[dataset_path][model_path][dataset_prompts_tokenized_subset_split_name].replace(\"Datasets/\", \"Models/\").split(\".\")[:-1])\n",
    "            if load_checkpoint > 0: model_path = model_name + f\"/checkpoint-{load_checkpoint}\"\n",
    "            logging_steps = datasets_subsets_logging_steps[dataset_path][dataset_prompts_tokenized_subset_split_name]\n",
    "            \n",
    "            print(f\"### Training model ({model_name}) ###\")\n",
    "            trained_model, model_test_results = train_model(model_path, model_name, logging_steps, dataset_prompts_tokenized_subset_split)\n",
    "            \n",
    "            trained_models[dataset_path][model_path][dataset_prompts_tokenized_subset_split_name] = trained_model\n",
    "            trained_models_subsets_datasets_tests_results[dataset_path][model_path][dataset_prompts_tokenized_subset_split_name] = model_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2428df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load trained models ###\n",
    "\n",
    "trained_models = {dataset_path: {model_path: {dataset_prompts_tokenized_subset_name:\n",
    "                  load_model(\"\".join(datasets_prompts_tokenized_subsets_paths[dataset_path][model_path][dataset_prompts_tokenized_subset_name].replace(\"Datasets/\", \"Models/\").split(\".\")[:-1]) + f\"/checkpoint-{load_checkpoint}\")\n",
    "                  for dataset_prompts_tokenized_subset_name in datasets_prompts_tokenized_subsets_sizes[dataset_path].keys()}\n",
    "                  for model_path in models_paths} for dataset_path in datasets_paths}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
